{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNT6nY0n5I6N",
        "outputId": "5f627e2f-aaa4-4214-e9d0-90c9a9013a82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape:  (19999, 43)\n",
            "Training attack category shape:  (19999,)\n",
            "Training labels shape:  (19999,)\n",
            "Test data shape:  (80650, 43)\n",
            "Test attack filtered category shape:  (80650,)\n",
            "Test labels filtered shape:  (80650,)\n",
            "Test data all shape:  (82332, 43)\n",
            "Test attack all category shape:  (82332,)\n",
            "Test labels all shape:  (82332,)\n",
            "Classification Report for Attack Category:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "           DoS       0.19      0.47      0.27      4089\n",
            "      Exploits       0.62      0.48      0.54     11132\n",
            "       Fuzzers       0.17      0.66      0.27      6062\n",
            "       Generic       0.99      0.52      0.68     18871\n",
            "        Normal       0.88      0.48      0.62     37000\n",
            "Reconnaissance       0.24      0.52      0.33      3496\n",
            "\n",
            "      accuracy                           0.51     80650\n",
            "     macro avg       0.51      0.52      0.45     80650\n",
            "  weighted avg       0.75      0.51      0.57     80650\n",
            "\n",
            "Confusion Matrix for Attack Category:\n",
            "[[ 1933   634   813     5   440   264]\n",
            " [ 2625  5361  1685    10   630   821]\n",
            " [  981    78  4030     8   402   563]\n",
            " [ 2426   297  5699  9768   386   295]\n",
            " [ 1989  1975 11167    89 17870  3910]\n",
            " [  222   249   594     0   606  1825]]\n",
            "Classification Report for Attack Label:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.48      0.62     37000\n",
            "           1       0.68      0.95      0.79     43650\n",
            "\n",
            "    accuracy                           0.73     80650\n",
            "   macro avg       0.78      0.71      0.71     80650\n",
            "weighted avg       0.78      0.73      0.72     80650\n",
            "\n",
            "Confusion Matrix for Attack Label:\n",
            "[[17870 19130]\n",
            " [ 2332 41318]]\n",
            "Classification Report for Attack Label All:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.48      0.62     37000\n",
            "           1       0.69      0.95      0.80     45332\n",
            "\n",
            "    accuracy                           0.74     82332\n",
            "   macro avg       0.79      0.71      0.71     82332\n",
            "weighted avg       0.78      0.74      0.72     82332\n",
            "\n",
            "Confusion Matrix for Attack Label All:\n",
            "[[17869 19131]\n",
            " [ 2424 42908]]\n",
            "CPU times: user 1min 1s, sys: 846 ms, total: 1min 2s\n",
            "Wall time: 1min 11s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "from re import X\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Load the training and test datasets\n",
        "train_data = pd.read_csv('UNSW_NB15_training-set-subset-subset.csv')\n",
        "test_data = pd.read_csv('UNSW_NB15_testing-set.csv')\n",
        "\n",
        "# Exclude specified attack categories\n",
        "exclude_categories = ['Analysis', 'Backdoor', 'Shellcode', 'Worms']\n",
        "train_data = train_data[~train_data['attack_cat'].isin(exclude_categories)]\n",
        "test_data_filtered = test_data[~test_data['attack_cat'].isin(exclude_categories)]\n",
        "\n",
        "# Separate features and labels for both datasets\n",
        "X_train = train_data.drop(['attack_cat', 'label'], axis=1)  # Drop both target columns\n",
        "y_train_attack_cat = train_data['attack_cat']  # Target for attack category\n",
        "y_train_label = train_data['label']  # Target for attack label\n",
        "\n",
        "X_test = test_data_filtered.drop(['attack_cat', 'label'], axis=1)\n",
        "y_test_attack_cat = test_data_filtered['attack_cat']\n",
        "y_test_label = test_data_filtered['label']\n",
        "\n",
        "X_test_all = test_data.drop(['attack_cat','label'], axis=1)\n",
        "y_test_attack_cat_all = test_data['attack_cat']\n",
        "y_test_label_all = test_data['label']\n",
        "\n",
        "print('Training data shape: ', X_train.shape)\n",
        "print('Training attack category shape: ', y_train_attack_cat.shape)\n",
        "print('Training labels shape: ', y_train_label.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test attack filtered category shape: ', y_test_attack_cat.shape)\n",
        "print('Test labels filtered shape: ', y_test_label.shape)\n",
        "print('Test data all shape: ', X_test_all.shape)\n",
        "print('Test attack all category shape: ', y_test_attack_cat_all.shape)\n",
        "print('Test labels all shape: ', y_test_label_all.shape)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Iterate through columns and encode string values\n",
        "for col in X_train.columns:\n",
        "    if X_train[col].dtype == 'object':  # Check if column is of object type (string)\n",
        "        # Fit the encoder on training data and transform both train and test data\n",
        "\n",
        "        # Get unique values from both train and test data for this column\n",
        "        unique_values = pd.concat([X_train[col], X_test[col]]).unique()\n",
        "\n",
        "        # Fit the encoder on the combined unique values\n",
        "        label_encoder.fit(unique_values)\n",
        "\n",
        "        X_train[col] = label_encoder.transform(X_train[col])\n",
        "        X_test[col] = label_encoder.transform(X_test[col])\n",
        "\n",
        "for col in X_test_all.columns:\n",
        "    if X_test_all[col].dtype == 'object':  # Check if column is of object type (string)\n",
        "        # Fit the encoder\n",
        "        label_encoder.fit(X_test_all[col])\n",
        "\n",
        "        X_test_all[col] = label_encoder.transform(X_test_all[col])\n",
        "\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "X_test_all = X_test_all.values\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_test_all_scaled = scaler.transform(X_test_all)\n",
        "\n",
        "# KNN\n",
        "# Attack Category\n",
        "knn_attack_cat = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_attack_cat.fit(X_train_scaled, y_train_attack_cat)\n",
        "\n",
        "knn_attack_cat_all = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_attack_cat_all.fit(X_train_scaled, y_train_attack_cat)\n",
        "\n",
        "# Attack Label prediction\n",
        "knn_label = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_label.fit(X_train_scaled, y_train_label)\n",
        "\n",
        "knn_label_all = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_label_all.fit(X_train_scaled, y_train_label)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_attack_cat = knn_attack_cat.predict(X_test_scaled)\n",
        "y_pred_label = knn_label.predict(X_test_scaled)\n",
        "\n",
        "y_pred_label_all = knn_label_all.predict(X_test_all_scaled)\n",
        "\n",
        "# Evaluate the models separately\n",
        "print(\"Classification Report for Attack Category:\")\n",
        "print(classification_report(y_test_attack_cat, y_pred_attack_cat))\n",
        "print(\"Confusion Matrix for Attack Category:\")\n",
        "print(confusion_matrix(y_test_attack_cat, y_pred_attack_cat))\n",
        "\n",
        "print(\"Classification Report for Attack Label:\")\n",
        "print(classification_report(y_test_label, y_pred_label))\n",
        "print(\"Confusion Matrix for Attack Label:\")\n",
        "print(confusion_matrix(y_test_label, y_pred_label))\n",
        "\n",
        "# For no filter\n",
        "print(\"Classification Report for Attack Label All:\")\n",
        "print(classification_report(y_test_label_all, y_pred_label_all))\n",
        "print(\"Confusion Matrix for Attack Label All:\")\n",
        "print(confusion_matrix(y_test_label_all, y_pred_label_all))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!pip install mealpy\n",
        "\n",
        "import numpy as np\n",
        "from mealpy import FloatVar, WOA\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "from re import X\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Load the training and test datasets\n",
        "train_data = pd.read_csv('UNSW_NB15_training-set-subset-subset.csv')\n",
        "test_data = pd.read_csv('UNSW_NB15_testing-set.csv')\n",
        "\n",
        "# Exclude specified attack categories\n",
        "exclude_categories = ['Analysis', 'Backdoor', 'Shellcode', 'Worms']\n",
        "train_data = train_data[~train_data['attack_cat'].isin(exclude_categories)]\n",
        "test_data_filtered = test_data[~test_data['attack_cat'].isin(exclude_categories)]\n",
        "\n",
        "# Separate features and labels for both datasets\n",
        "X_train = train_data.drop(['attack_cat', 'label'], axis=1)  # Drop both target columns\n",
        "y_train_attack_cat = train_data['attack_cat']  # Target for attack category\n",
        "y_train_label = train_data['label']  # Target for attack label\n",
        "\n",
        "X_test = test_data_filtered.drop(['attack_cat', 'label'], axis=1)\n",
        "y_test_attack_cat = test_data_filtered['attack_cat']\n",
        "y_test_label = test_data_filtered['label']\n",
        "\n",
        "X_test_all = test_data.drop(['attack_cat','label'], axis=1)\n",
        "y_test_attack_cat_all = test_data['attack_cat']\n",
        "y_test_label_all = test_data['label']\n",
        "\n",
        "print('Training data shape: ', X_train.shape)\n",
        "print('Training attack category shape: ', y_train_attack_cat.shape)\n",
        "print('Training labels shape: ', y_train_label.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test attack filtered category shape: ', y_test_attack_cat.shape)\n",
        "print('Test labels filtered shape: ', y_test_label.shape)\n",
        "print('Test data all shape: ', X_test_all.shape)\n",
        "print('Test attack all category shape: ', y_test_attack_cat_all.shape)\n",
        "print('Test labels all shape: ', y_test_label_all.shape)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Iterate through columns and encode string values\n",
        "for col in X_train.columns:\n",
        "    if X_train[col].dtype == 'object':  # Check if column is of object type (string)\n",
        "        # Fit the encoder on training data and transform both train and test data\n",
        "\n",
        "        # Get unique values from both train and test data for this column\n",
        "        unique_values = pd.concat([X_train[col], X_test[col]]).unique()\n",
        "\n",
        "        # Fit the encoder on the combined unique values\n",
        "        label_encoder.fit(unique_values)\n",
        "\n",
        "        X_train[col] = label_encoder.transform(X_train[col])\n",
        "        X_test[col] = label_encoder.transform(X_test[col])\n",
        "\n",
        "for col in X_test_all.columns:\n",
        "    if X_test_all[col].dtype == 'object':  # Check if column is of object type (string)\n",
        "        # Fit the encoder\n",
        "        label_encoder.fit(X_test_all[col])\n",
        "\n",
        "        X_test_all[col] = label_encoder.transform(X_test_all[col])\n",
        "\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "X_test_all = X_test_all.values\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_test_all_scaled = scaler.transform(X_test_all)\n",
        "\n",
        "def objective_function_knn_multi(solution):\n",
        "    # Extract k value from solution (assuming solution[0] represents k)\n",
        "    k = int(round(solution[0]))\n",
        "\n",
        "    # Limit k from 1 to 30\n",
        "    k = max(1, min(k, 30))\n",
        "\n",
        "    # Create and train KNN model\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn_model.fit(X_train_scaled, y_train_label)\n",
        "\n",
        "    # Predict on test set and calculate accuracy and F1-score\n",
        "    y_pred = knn_model.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test_label, y_pred)\n",
        "    f1 = f1_score(y_test_label, y_pred)\n",
        "\n",
        "    # Since WOA minimizes, return 1 - accuracy and 1 - F1-score to maximize both\n",
        "    return 1 - accuracy, 1 - f1\n",
        "\n",
        "# Define the optimization problem\n",
        "problem_dict = {\n",
        "    \"obj_func\": objective_function_knn_multi,  # Objective function\n",
        "    \"bounds\": FloatVar(lb=[1], ub=[30], name=\"k\"),  # Bounds for k\n",
        "    \"minmax\": \"min\",  # Minimize (since we are inverting accuracy and F1-score)\n",
        "    \"obj_weights\": [0.5, 0.5]  # Equal weights for accuracy and F1-score\n",
        "}\n",
        "\n",
        "# Create and run the WOA optimizer\n",
        "model = WOA.OriginalWOA(epoch=3, pop_size=30)\n",
        "ideal_k = model.solve(problem_dict)\n",
        "\n",
        "print(ideal_k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTjZMQ2F6SD9",
        "outputId": "815d8a35-47c7-4165-b3bd-669a1e7f1d2e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mealpy in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.10/dist-packages (from mealpy) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from mealpy) (3.8.0)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mealpy) (1.13.1)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from mealpy) (2.2.2)\n",
            "Requirement already satisfied: opfunu>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from mealpy) (1.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.27.0 in /usr/local/lib/python3.10/dist-packages (from opfunu>=1.0.0->mealpy) (2.32.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->mealpy) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->mealpy) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->mealpy) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.0->opfunu>=1.0.0->mealpy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.0->opfunu>=1.0.0->mealpy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.0->opfunu>=1.0.0->mealpy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.0->opfunu>=1.0.0->mealpy) (2024.8.30)\n",
            "Training data shape:  (19999, 43)\n",
            "Training attack category shape:  (19999,)\n",
            "Training labels shape:  (19999,)\n",
            "Test data shape:  (80650, 43)\n",
            "Test attack filtered category shape:  (80650,)\n",
            "Test labels filtered shape:  (80650,)\n",
            "Test data all shape:  (82332, 43)\n",
            "Test attack all category shape:  (82332,)\n",
            "Test labels all shape:  (82332,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:mealpy.swarm_based.WOA.OriginalWOA:Solving 2-objective optimization problem with weights: [0.5 0.5].\n",
            "INFO:mealpy.swarm_based.WOA.OriginalWOA:>>>Problem: P, Epoch: 1, Current best: 0.21333143380643738, Global best: 0.21333143380643738, Runtime: 572.80918 seconds\n",
            "INFO:mealpy.swarm_based.WOA.OriginalWOA:>>>Problem: P, Epoch: 2, Current best: 0.21333143380643738, Global best: 0.21333143380643738, Runtime: 579.11450 seconds\n",
            "INFO:mealpy.swarm_based.WOA.OriginalWOA:>>>Problem: P, Epoch: 3, Current best: 0.21333143380643738, Global best: 0.21333143380643738, Runtime: 577.99299 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id: 370, target: Objectives: [0.24239306 0.18426981], Fitness: 0.21333143380643738, solution: [22.52362177]\n",
            "CPU times: user 38min 20s, sys: 25.8 s, total: 38min 46s\n",
            "Wall time: 39min 4s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "from re import X\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Load the training and test datasets\n",
        "train_data = pd.read_csv('UNSW_NB15_training-set-subset-subset.csv')\n",
        "test_data = pd.read_csv('UNSW_NB15_testing-set.csv')\n",
        "\n",
        "# Exclude specified attack categories\n",
        "exclude_categories = ['Analysis', 'Backdoor', 'Shellcode', 'Worms']\n",
        "train_data = train_data[~train_data['attack_cat'].isin(exclude_categories)]\n",
        "test_data_filtered = test_data[~test_data['attack_cat'].isin(exclude_categories)]\n",
        "\n",
        "# Separate features and labels for both datasets\n",
        "X_train = train_data.drop(['attack_cat', 'label'], axis=1)  # Drop both target columns\n",
        "y_train_attack_cat = train_data['attack_cat']  # Target for attack category\n",
        "y_train_label = train_data['label']  # Target for attack label\n",
        "\n",
        "X_test = test_data_filtered.drop(['attack_cat', 'label'], axis=1)\n",
        "y_test_attack_cat = test_data_filtered['attack_cat']\n",
        "y_test_label = test_data_filtered['label']\n",
        "\n",
        "X_test_all = test_data.drop(['attack_cat','label'], axis=1)\n",
        "y_test_attack_cat_all = test_data['attack_cat']\n",
        "y_test_label_all = test_data['label']\n",
        "\n",
        "print('Training data shape: ', X_train.shape)\n",
        "print('Training attack category shape: ', y_train_attack_cat.shape)\n",
        "print('Training labels shape: ', y_train_label.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test attack filtered category shape: ', y_test_attack_cat.shape)\n",
        "print('Test labels filtered shape: ', y_test_label.shape)\n",
        "print('Test data all shape: ', X_test_all.shape)\n",
        "print('Test attack all category shape: ', y_test_attack_cat_all.shape)\n",
        "print('Test labels all shape: ', y_test_label_all.shape)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Iterate through columns and encode string values\n",
        "for col in X_train.columns:\n",
        "    if X_train[col].dtype == 'object':  # Check if column is of object type (string)\n",
        "        # Fit the encoder on training data and transform both train and test data\n",
        "\n",
        "        # Get unique values from both train and test data for this column\n",
        "        unique_values = pd.concat([X_train[col], X_test[col]]).unique()\n",
        "\n",
        "        # Fit the encoder on the combined unique values\n",
        "        label_encoder.fit(unique_values)\n",
        "\n",
        "        X_train[col] = label_encoder.transform(X_train[col])\n",
        "        X_test[col] = label_encoder.transform(X_test[col])\n",
        "\n",
        "for col in X_test_all.columns:\n",
        "    if X_test_all[col].dtype == 'object':  # Check if column is of object type (string)\n",
        "        # Fit the encoder\n",
        "        label_encoder.fit(X_test_all[col])\n",
        "\n",
        "        X_test_all[col] = label_encoder.transform(X_test_all[col])\n",
        "\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "X_test_all = X_test_all.values\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_test_all_scaled = scaler.transform(X_test_all)\n",
        "\n",
        "# KNN\n",
        "# Attack Category\n",
        "knn_attack_cat = KNeighborsClassifier(n_neighbors=22)\n",
        "knn_attack_cat.fit(X_train_scaled, y_train_attack_cat)\n",
        "\n",
        "knn_attack_cat_all = KNeighborsClassifier(n_neighbors=22)\n",
        "knn_attack_cat_all.fit(X_train_scaled, y_train_attack_cat)\n",
        "\n",
        "# Attack Label prediction\n",
        "knn_label = KNeighborsClassifier(n_neighbors=22)\n",
        "knn_label.fit(X_train_scaled, y_train_label)\n",
        "\n",
        "knn_label_all = KNeighborsClassifier(n_neighbors=22)\n",
        "knn_label_all.fit(X_train_scaled, y_train_label)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_attack_cat = knn_attack_cat.predict(X_test_scaled)\n",
        "y_pred_label = knn_label.predict(X_test_scaled)\n",
        "\n",
        "y_pred_label_all = knn_label_all.predict(X_test_all_scaled)\n",
        "\n",
        "# Evaluate the models separately\n",
        "print(\"Classification Report for Attack Category:\")\n",
        "print(classification_report(y_test_attack_cat, y_pred_attack_cat))\n",
        "print(\"Confusion Matrix for Attack Category:\")\n",
        "print(confusion_matrix(y_test_attack_cat, y_pred_attack_cat))\n",
        "\n",
        "print(\"Classification Report for Attack Label:\")\n",
        "print(classification_report(y_test_label, y_pred_label))\n",
        "print(\"Confusion Matrix for Attack Label:\")\n",
        "print(confusion_matrix(y_test_label, y_pred_label))\n",
        "\n",
        "# For no filter\n",
        "print(\"Classification Report for Attack Label All:\")\n",
        "print(classification_report(y_test_label_all, y_pred_label_all))\n",
        "print(\"Confusion Matrix for Attack Label All:\")\n",
        "print(confusion_matrix(y_test_label_all, y_pred_label_all))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGwPiHEqb1d6",
        "outputId": "dcb084b0-e1ea-4bf8-caeb-4cb0bdcffe0b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape:  (19999, 43)\n",
            "Training attack category shape:  (19999,)\n",
            "Training labels shape:  (19999,)\n",
            "Test data shape:  (80650, 43)\n",
            "Test attack filtered category shape:  (80650,)\n",
            "Test labels filtered shape:  (80650,)\n",
            "Test data all shape:  (82332, 43)\n",
            "Test attack all category shape:  (82332,)\n",
            "Test labels all shape:  (82332,)\n",
            "Classification Report for Attack Category:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "           DoS       0.23      0.56      0.32      4089\n",
            "      Exploits       0.61      0.50      0.55     11132\n",
            "       Fuzzers       0.17      0.72      0.28      6062\n",
            "       Generic       0.97      0.56      0.71     18871\n",
            "        Normal       0.97      0.48      0.64     37000\n",
            "Reconnaissance       0.30      0.59      0.40      3496\n",
            "\n",
            "      accuracy                           0.53     80650\n",
            "     macro avg       0.54      0.57      0.48     80650\n",
            "  weighted avg       0.80      0.53      0.59     80650\n",
            "\n",
            "Confusion Matrix for Attack Category:\n",
            "[[ 2275   655   894     8    30   227]\n",
            " [ 2508  5605  1915    16   149   939]\n",
            " [ 1023    95  4375    19   116   434]\n",
            " [ 2839   307  4834 10484   193   214]\n",
            " [  990  2252 12758   238 17832  2930]\n",
            " [  304   327   795     1    13  2056]]\n",
            "Classification Report for Attack Label:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.48      0.65     37000\n",
            "           1       0.69      0.99      0.82     43650\n",
            "\n",
            "    accuracy                           0.76     80650\n",
            "   macro avg       0.83      0.74      0.73     80650\n",
            "weighted avg       0.82      0.76      0.74     80650\n",
            "\n",
            "Confusion Matrix for Attack Label:\n",
            "[[17840 19160]\n",
            " [  419 43231]]\n",
            "Classification Report for Attack Label All:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.48      0.65     37000\n",
            "           1       0.70      0.99      0.82     45332\n",
            "\n",
            "    accuracy                           0.76     82332\n",
            "   macro avg       0.84      0.74      0.73     82332\n",
            "weighted avg       0.82      0.76      0.74     82332\n",
            "\n",
            "Confusion Matrix for Attack Label All:\n",
            "[[17840 19160]\n",
            " [  423 44909]]\n",
            "CPU times: user 1min 4s, sys: 567 ms, total: 1min 4s\n",
            "Wall time: 1min 9s\n"
          ]
        }
      ]
    }
  ]
}