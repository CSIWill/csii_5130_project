{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_15w7qVeAQpf",
        "outputId": "795d60a2-96a6-4b37-ec4b-d9127348314c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape:  (19999, 43)\n",
            "Training attack category shape:  (19999,)\n",
            "Training labels shape:  (19999,)\n",
            "Test data shape:  (80650, 43)\n",
            "Test attack filtered category shape:  (80650,)\n",
            "Test labels filtered shape:  (80650,)\n",
            "Test data all shape:  (82332, 43)\n",
            "Test attack all category shape:  (82332,)\n",
            "Test labels all shape:  (82332,)\n",
            "Classification Report for Attack Category:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "           DoS       0.19      0.47      0.27      4089\n",
            "      Exploits       0.62      0.48      0.54     11132\n",
            "       Fuzzers       0.17      0.66      0.27      6062\n",
            "       Generic       0.99      0.52      0.68     18871\n",
            "        Normal       0.88      0.48      0.62     37000\n",
            "Reconnaissance       0.24      0.52      0.33      3496\n",
            "\n",
            "      accuracy                           0.51     80650\n",
            "     macro avg       0.51      0.52      0.45     80650\n",
            "  weighted avg       0.75      0.51      0.57     80650\n",
            "\n",
            "Confusion Matrix for Attack Category:\n",
            "[[ 1933   634   813     5   440   264]\n",
            " [ 2625  5361  1685    10   630   821]\n",
            " [  981    78  4030     8   402   563]\n",
            " [ 2426   297  5699  9768   386   295]\n",
            " [ 1989  1975 11167    89 17870  3910]\n",
            " [  222   249   594     0   606  1825]]\n",
            "Classification Report for Attack Label:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.48      0.62     37000\n",
            "           1       0.68      0.95      0.79     43650\n",
            "\n",
            "    accuracy                           0.73     80650\n",
            "   macro avg       0.78      0.71      0.71     80650\n",
            "weighted avg       0.78      0.73      0.72     80650\n",
            "\n",
            "Confusion Matrix for Attack Label:\n",
            "[[17870 19130]\n",
            " [ 2332 41318]]\n",
            "Classification Report for Attack Label All:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.48      0.62     37000\n",
            "           1       0.69      0.95      0.80     45332\n",
            "\n",
            "    accuracy                           0.74     82332\n",
            "   macro avg       0.79      0.71      0.71     82332\n",
            "weighted avg       0.78      0.74      0.72     82332\n",
            "\n",
            "Confusion Matrix for Attack Label All:\n",
            "[[17869 19131]\n",
            " [ 2424 42908]]\n",
            "CPU times: user 1min 6s, sys: 542 ms, total: 1min 7s\n",
            "Wall time: 1min 9s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "from re import X\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Load the training and test datasets\n",
        "train_data = pd.read_csv('UNSW_NB15_training-set-subset-subset.csv')\n",
        "test_data = pd.read_csv('UNSW_NB15_testing-set.csv')\n",
        "\n",
        "# Exclude specified attack categories\n",
        "exclude_categories = ['Analysis', 'Backdoor', 'Shellcode', 'Worms']\n",
        "train_data = train_data[~train_data['attack_cat'].isin(exclude_categories)]\n",
        "test_data_filtered = test_data[~test_data['attack_cat'].isin(exclude_categories)]\n",
        "\n",
        "# Separate features and labels for both datasets\n",
        "X_train = train_data.drop(['attack_cat', 'label'], axis=1)  # Drop both target columns\n",
        "y_train_attack_cat = train_data['attack_cat']  # Target for attack category\n",
        "y_train_label = train_data['label']  # Target for attack label\n",
        "\n",
        "X_test = test_data_filtered.drop(['attack_cat', 'label'], axis=1)\n",
        "y_test_attack_cat = test_data_filtered['attack_cat']\n",
        "y_test_label = test_data_filtered['label']\n",
        "\n",
        "X_test_all = test_data.drop(['attack_cat','label'], axis=1)\n",
        "y_test_attack_cat_all = test_data['attack_cat']\n",
        "y_test_label_all = test_data['label']\n",
        "\n",
        "print('Training data shape: ', X_train.shape)\n",
        "print('Training attack category shape: ', y_train_attack_cat.shape)\n",
        "print('Training labels shape: ', y_train_label.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test attack filtered category shape: ', y_test_attack_cat.shape)\n",
        "print('Test labels filtered shape: ', y_test_label.shape)\n",
        "print('Test data all shape: ', X_test_all.shape)\n",
        "print('Test attack all category shape: ', y_test_attack_cat_all.shape)\n",
        "print('Test labels all shape: ', y_test_label_all.shape)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Iterate through columns and encode string values\n",
        "for col in X_train.columns:\n",
        "    if X_train[col].dtype == 'object':  # Check if column is of object type (string)\n",
        "        # Fit the encoder on training data and transform both train and test data\n",
        "\n",
        "        # Get unique values from both train and test data for this column\n",
        "        unique_values = pd.concat([X_train[col], X_test[col]]).unique()\n",
        "\n",
        "        # Fit the encoder on the combined unique values\n",
        "        label_encoder.fit(unique_values)\n",
        "\n",
        "        X_train[col] = label_encoder.transform(X_train[col])\n",
        "        X_test[col] = label_encoder.transform(X_test[col])\n",
        "\n",
        "for col in X_test_all.columns:\n",
        "    if X_test_all[col].dtype == 'object':  # Check if column is of object type (string)\n",
        "        # Fit the encoder\n",
        "        label_encoder.fit(X_test_all[col])\n",
        "\n",
        "        X_test_all[col] = label_encoder.transform(X_test_all[col])\n",
        "\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "X_test_all = X_test_all.values\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_test_all_scaled = scaler.transform(X_test_all)\n",
        "\n",
        "# KNN\n",
        "# Attack Category\n",
        "knn_attack_cat = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_attack_cat.fit(X_train_scaled, y_train_attack_cat)\n",
        "\n",
        "knn_attack_cat_all = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_attack_cat_all.fit(X_train_scaled, y_train_attack_cat)\n",
        "\n",
        "# Attack Label prediction\n",
        "knn_label = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_label.fit(X_train_scaled, y_train_label)\n",
        "\n",
        "knn_label_all = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_label_all.fit(X_train_scaled, y_train_label)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_attack_cat = knn_attack_cat.predict(X_test_scaled)\n",
        "y_pred_label = knn_label.predict(X_test_scaled)\n",
        "\n",
        "y_pred_label_all = knn_label_all.predict(X_test_all_scaled)\n",
        "\n",
        "# Evaluate the models separately\n",
        "print(\"Classification Report for Attack Category:\")\n",
        "print(classification_report(y_test_attack_cat, y_pred_attack_cat))\n",
        "print(\"Confusion Matrix for Attack Category:\")\n",
        "print(confusion_matrix(y_test_attack_cat, y_pred_attack_cat))\n",
        "\n",
        "print(\"Classification Report for Attack Label:\")\n",
        "print(classification_report(y_test_label, y_pred_label))\n",
        "print(\"Confusion Matrix for Attack Label:\")\n",
        "print(confusion_matrix(y_test_label, y_pred_label))\n",
        "\n",
        "# For no filter\n",
        "print(\"Classification Report for Attack Label All:\")\n",
        "print(classification_report(y_test_label_all, y_pred_label_all))\n",
        "print(\"Confusion Matrix for Attack Label All:\")\n",
        "print(confusion_matrix(y_test_label_all, y_pred_label_all))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mealpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoXLOSEbAYT3",
        "outputId": "5b398493-0e1d-4d38-9f8a-45fec273dde9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mealpy\n",
            "  Downloading mealpy-3.0.1-py3-none-any.whl.metadata (104 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/104.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.10/dist-packages (from mealpy) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from mealpy) (3.8.0)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mealpy) (1.13.1)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from mealpy) (2.2.2)\n",
            "Collecting opfunu>=1.0.0 (from mealpy)\n",
            "  Downloading opfunu-1.0.4-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.27.0 in /usr/local/lib/python3.10/dist-packages (from opfunu>=1.0.0->mealpy) (2.32.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->mealpy) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->mealpy) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->mealpy) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.0->opfunu>=1.0.0->mealpy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.0->opfunu>=1.0.0->mealpy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.0->opfunu>=1.0.0->mealpy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.0->opfunu>=1.0.0->mealpy) (2024.8.30)\n",
            "Downloading mealpy-3.0.1-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.3/386.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opfunu-1.0.4-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opfunu, mealpy\n",
            "Successfully installed mealpy-3.0.1 opfunu-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "import numpy as np\n",
        "from mealpy import PSO, FloatVar\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "from re import X\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Load the training and test datasets\n",
        "train_data = pd.read_csv('UNSW_NB15_training-set-subset-subset.csv')\n",
        "test_data = pd.read_csv('UNSW_NB15_testing-set.csv')\n",
        "\n",
        "# Exclude specified attack categories\n",
        "exclude_categories = ['Analysis', 'Backdoor', 'Shellcode', 'Worms']\n",
        "train_data = train_data[~train_data['attack_cat'].isin(exclude_categories)]\n",
        "test_data_filtered = test_data[~test_data['attack_cat'].isin(exclude_categories)]\n",
        "\n",
        "# Separate features and labels for both datasets\n",
        "X_train = train_data.drop(['attack_cat', 'label'], axis=1)  # Drop both target columns\n",
        "y_train_attack_cat = train_data['attack_cat']  # Target for attack category\n",
        "y_train_label = train_data['label']  # Target for attack label\n",
        "\n",
        "X_test = test_data_filtered.drop(['attack_cat', 'label'], axis=1)\n",
        "y_test_attack_cat = test_data_filtered['attack_cat']\n",
        "y_test_label = test_data_filtered['label']\n",
        "\n",
        "X_test_all = test_data.drop(['attack_cat','label'], axis=1)\n",
        "y_test_attack_cat_all = test_data['attack_cat']\n",
        "y_test_label_all = test_data['label']\n",
        "\n",
        "print('Training data shape: ', X_train.shape)\n",
        "print('Training attack category shape: ', y_train_attack_cat.shape)\n",
        "print('Training labels shape: ', y_train_label.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test attack filtered category shape: ', y_test_attack_cat.shape)\n",
        "print('Test labels filtered shape: ', y_test_label.shape)\n",
        "print('Test data all shape: ', X_test_all.shape)\n",
        "print('Test attack all category shape: ', y_test_attack_cat_all.shape)\n",
        "print('Test labels all shape: ', y_test_label_all.shape)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Iterate through columns and encode string values\n",
        "for col in X_train.columns:\n",
        "    if X_train[col].dtype == 'object':  # Check if column is of object type (string)\n",
        "        # Fit the encoder on training data and transform both train and test data\n",
        "\n",
        "        # Get unique values from both train and test data for this column\n",
        "        unique_values = pd.concat([X_train[col], X_test[col]]).unique()\n",
        "\n",
        "        # Fit the encoder on the combined unique values\n",
        "        label_encoder.fit(unique_values)\n",
        "\n",
        "        X_train[col] = label_encoder.transform(X_train[col])\n",
        "        X_test[col] = label_encoder.transform(X_test[col])\n",
        "\n",
        "for col in X_test_all.columns:\n",
        "    if X_test_all[col].dtype == 'object':  # Check if column is of object type (string)\n",
        "        # Fit the encoder\n",
        "        label_encoder.fit(X_test_all[col])\n",
        "\n",
        "        X_test_all[col] = label_encoder.transform(X_test_all[col])\n",
        "\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "X_test_all = X_test_all.values\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_test_all_scaled = scaler.transform(X_test_all)\n",
        "\n",
        "def objective_function_knn_multi(solution):\n",
        "    # Extract k value from solution (assuming solution[0] represents k)\n",
        "    k = int(round(solution[0]))\n",
        "\n",
        "    # Limit k from 1 to 30\n",
        "    k = max(1, min(k, 30))\n",
        "\n",
        "    # Create and train KNN model\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn_model.fit(X_train_scaled, y_train_label)\n",
        "\n",
        "    # Predict on test set and calculate accuracy and F1-score\n",
        "    y_pred = knn_model.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test_label, y_pred)\n",
        "    f1 = f1_score(y_test_label, y_pred)\n",
        "\n",
        "    # Since PSO minimizes, return 1 - accuracy and 1 - F1-score to maximize both\n",
        "    return 1 - accuracy, 1 - f1\n",
        "\n",
        "# Define the optimization problem\n",
        "problem_dict = {\n",
        "    \"obj_func\": objective_function_knn_multi,  # Objective function\n",
        "    \"bounds\": FloatVar(lb=[1], ub=[30], name=\"k\"),  # Bounds for k\n",
        "    \"minmax\": \"min\",  # Minimize (since we are inverting accuracy and F1-score)\n",
        "    \"obj_weights\": [0.5, 0.5]  # Equal weights for accuracy and F1-score\n",
        "}\n",
        "\n",
        "# Create and run the PSO optimizer\n",
        "model = PSO.OriginalPSO(epoch=3, pop_size=30)\n",
        "ideal_k = model.solve(problem_dict)\n",
        "\n",
        "print(ideal_k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdUB07GqW_Or",
        "outputId": "01f87e82-908c-49ca-9d2f-cdf840785397"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape:  (19999, 43)\n",
            "Training attack category shape:  (19999,)\n",
            "Training labels shape:  (19999,)\n",
            "Test data shape:  (80650, 43)\n",
            "Test attack filtered category shape:  (80650,)\n",
            "Test labels filtered shape:  (80650,)\n",
            "Test data all shape:  (82332, 43)\n",
            "Test attack all category shape:  (82332,)\n",
            "Test labels all shape:  (82332,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:mealpy.swarm_based.PSO.OriginalPSO:Solving 2-objective optimization problem with weights: [0.5 0.5].\n",
            "INFO:mealpy.swarm_based.PSO.OriginalPSO:>>>Problem: P, Epoch: 1, Current best: 0.21333143380643738, Global best: 0.21333143380643738, Runtime: 586.80061 seconds\n",
            "INFO:mealpy.swarm_based.PSO.OriginalPSO:>>>Problem: P, Epoch: 2, Current best: 0.21333143380643738, Global best: 0.21333143380643738, Runtime: 590.22088 seconds\n",
            "INFO:mealpy.swarm_based.PSO.OriginalPSO:>>>Problem: P, Epoch: 3, Current best: 0.21333143380643738, Global best: 0.21333143380643738, Runtime: 586.07919 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id: 2308, target: Objectives: [0.24239306 0.18426981], Fitness: 0.21333143380643738, solution: [23.18200107]\n",
            "CPU times: user 38min 52s, sys: 21.2 s, total: 39min 13s\n",
            "Wall time: 39min 31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "from re import X\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Load the training and test datasets\n",
        "train_data = pd.read_csv('UNSW_NB15_training-set-subset-subset.csv')\n",
        "test_data = pd.read_csv('UNSW_NB15_testing-set.csv')\n",
        "\n",
        "# Exclude specified attack categories\n",
        "exclude_categories = ['Analysis', 'Backdoor', 'Shellcode', 'Worms']\n",
        "train_data = train_data[~train_data['attack_cat'].isin(exclude_categories)]\n",
        "test_data_filtered = test_data[~test_data['attack_cat'].isin(exclude_categories)]\n",
        "\n",
        "# Separate features and labels for both datasets\n",
        "X_train = train_data.drop(['attack_cat', 'label'], axis=1)  # Drop both target columns\n",
        "y_train_attack_cat = train_data['attack_cat']  # Target for attack category\n",
        "y_train_label = train_data['label']  # Target for attack label\n",
        "\n",
        "X_test = test_data_filtered.drop(['attack_cat', 'label'], axis=1)\n",
        "y_test_attack_cat = test_data_filtered['attack_cat']\n",
        "y_test_label = test_data_filtered['label']\n",
        "\n",
        "X_test_all = test_data.drop(['attack_cat','label'], axis=1)\n",
        "y_test_attack_cat_all = test_data['attack_cat']\n",
        "y_test_label_all = test_data['label']\n",
        "\n",
        "print('Training data shape: ', X_train.shape)\n",
        "print('Training attack category shape: ', y_train_attack_cat.shape)\n",
        "print('Training labels shape: ', y_train_label.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test attack filtered category shape: ', y_test_attack_cat.shape)\n",
        "print('Test labels filtered shape: ', y_test_label.shape)\n",
        "print('Test data all shape: ', X_test_all.shape)\n",
        "print('Test attack all category shape: ', y_test_attack_cat_all.shape)\n",
        "print('Test labels all shape: ', y_test_label_all.shape)\n",
        "\n",
        "# Create a LabelEncoder object\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Iterate through columns and encode string values\n",
        "for col in X_train.columns:\n",
        "    if X_train[col].dtype == 'object':  # Check if column is of object type (string)\n",
        "        # Fit the encoder on training data and transform both train and test data\n",
        "\n",
        "        # Get unique values from both train and test data for this column\n",
        "        unique_values = pd.concat([X_train[col], X_test[col]]).unique()\n",
        "\n",
        "        # Fit the encoder on the combined unique values\n",
        "        label_encoder.fit(unique_values)\n",
        "\n",
        "        X_train[col] = label_encoder.transform(X_train[col])\n",
        "        X_test[col] = label_encoder.transform(X_test[col])\n",
        "\n",
        "for col in X_test_all.columns:\n",
        "    if X_test_all[col].dtype == 'object':  # Check if column is of object type (string)\n",
        "        # Fit the encoder\n",
        "        label_encoder.fit(X_test_all[col])\n",
        "\n",
        "        X_test_all[col] = label_encoder.transform(X_test_all[col])\n",
        "\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "X_test_all = X_test_all.values\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_test_all_scaled = scaler.transform(X_test_all)\n",
        "\n",
        "# KNN\n",
        "# Attack Category\n",
        "knn_attack_cat = KNeighborsClassifier(n_neighbors=23)\n",
        "knn_attack_cat.fit(X_train_scaled, y_train_attack_cat)\n",
        "\n",
        "knn_attack_cat_all = KNeighborsClassifier(n_neighbors=23)\n",
        "knn_attack_cat_all.fit(X_train_scaled, y_train_attack_cat)\n",
        "\n",
        "# Attack Label prediction\n",
        "knn_label = KNeighborsClassifier(n_neighbors=23)\n",
        "knn_label.fit(X_train_scaled, y_train_label)\n",
        "\n",
        "knn_label_all = KNeighborsClassifier(n_neighbors=23)\n",
        "knn_label_all.fit(X_train_scaled, y_train_label)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_attack_cat = knn_attack_cat.predict(X_test_scaled)\n",
        "y_pred_label = knn_label.predict(X_test_scaled)\n",
        "\n",
        "y_pred_label_all = knn_label_all.predict(X_test_all_scaled)\n",
        "\n",
        "# Evaluate the models separately\n",
        "print(\"Classification Report for Attack Category:\")\n",
        "print(classification_report(y_test_attack_cat, y_pred_attack_cat))\n",
        "print(\"Confusion Matrix for Attack Category:\")\n",
        "print(confusion_matrix(y_test_attack_cat, y_pred_attack_cat))\n",
        "\n",
        "print(\"Classification Report for Attack Label:\")\n",
        "print(classification_report(y_test_label, y_pred_label))\n",
        "print(\"Confusion Matrix for Attack Label:\")\n",
        "print(confusion_matrix(y_test_label, y_pred_label))\n",
        "\n",
        "# For no filter\n",
        "print(\"Classification Report for Attack Label All:\")\n",
        "print(classification_report(y_test_label_all, y_pred_label_all))\n",
        "print(\"Confusion Matrix for Attack Label All:\")\n",
        "print(confusion_matrix(y_test_label_all, y_pred_label_all))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSo8K-goH3IU",
        "outputId": "ec3ce3c3-9018-4a34-d14f-b1fc860f348d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape:  (19999, 43)\n",
            "Training attack category shape:  (19999,)\n",
            "Training labels shape:  (19999,)\n",
            "Test data shape:  (80650, 43)\n",
            "Test attack filtered category shape:  (80650,)\n",
            "Test labels filtered shape:  (80650,)\n",
            "Test data all shape:  (82332, 43)\n",
            "Test attack all category shape:  (82332,)\n",
            "Test labels all shape:  (82332,)\n",
            "Classification Report for Attack Category:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "           DoS       0.23      0.55      0.32      4089\n",
            "      Exploits       0.61      0.50      0.55     11132\n",
            "       Fuzzers       0.17      0.72      0.28      6062\n",
            "       Generic       0.97      0.56      0.71     18871\n",
            "        Normal       0.97      0.48      0.64     37000\n",
            "Reconnaissance       0.30      0.59      0.40      3496\n",
            "\n",
            "      accuracy                           0.53     80650\n",
            "     macro avg       0.54      0.57      0.48     80650\n",
            "  weighted avg       0.80      0.53      0.59     80650\n",
            "\n",
            "Confusion Matrix for Attack Category:\n",
            "[[ 2269   656   898     8    31   227]\n",
            " [ 2495  5593  1931    16   149   948]\n",
            " [ 1016    98  4371    19   123   435]\n",
            " [ 2854   305  4802 10541   164   205]\n",
            " [  988  2261 12677   255 17832  2987]\n",
            " [  300   329   793     1    13  2060]]\n",
            "Classification Report for Attack Label:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.48      0.65     37000\n",
            "           1       0.69      0.99      0.82     43650\n",
            "\n",
            "    accuracy                           0.76     80650\n",
            "   macro avg       0.84      0.74      0.73     80650\n",
            "weighted avg       0.82      0.76      0.74     80650\n",
            "\n",
            "Confusion Matrix for Attack Label:\n",
            "[[17831 19169]\n",
            " [  380 43270]]\n",
            "Classification Report for Attack Label All:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.48      0.65     37000\n",
            "           1       0.70      0.99      0.82     45332\n",
            "\n",
            "    accuracy                           0.76     82332\n",
            "   macro avg       0.84      0.74      0.73     82332\n",
            "weighted avg       0.83      0.76      0.74     82332\n",
            "\n",
            "Confusion Matrix for Attack Label All:\n",
            "[[17831 19169]\n",
            " [  384 44948]]\n",
            "CPU times: user 1min 1s, sys: 590 ms, total: 1min 2s\n",
            "Wall time: 1min 2s\n"
          ]
        }
      ]
    }
  ]
}